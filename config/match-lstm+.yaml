data:
  dataset:
    train_path: data/SQuAD/train-v1.1.json
    dev_path: data/SQuAD/dev-v1.1.json
  dataset_h5: data/squad_glove.h5
  ignore_max_len: 700 # context token len > ignore_max_len will be dropped

  embedding_path: data/glove.840B.300d.zip

  model_path: data/model-weight.pt
  checkpoint_path: data/checkpoint

model:
  random_seed: 123
  dropout_p: 0.2

  word_embedding_size: 300
  char_embedding_size: 300
  hidden_size: 150  # one-direction

  encoder_word_layers: 1
  encoder_char_layers: 1
  encoder_bidirection: True
  char_trainable: False
  enable_char: True
  mix_encode: False # whether word and char the same encoder

  match_lstm_bidirection: True
  self_match_lstm_bidirection: True
  self_match_lstm: False

  birnn_after_self: False
  init_ptr_hidden: linear # pooling, bi-pooling, linear, None
  ptr_bidirection: False
  answer_search: True

  hidden_mode: GRU # LSTM or GRU
  gated_attention: True

train:
  batch_size: 32
  valid_batch_size: 32
  epoch: 30
  enable_cuda: False

  optimizer: 'adamax'  # adam, sgd, adamax, adadelta(default is adamax)
  learning_rate: 0.002  # only for sgd
  clip_grad_norm: 5

test:
  batch_size: 32
  enable_cuda: False